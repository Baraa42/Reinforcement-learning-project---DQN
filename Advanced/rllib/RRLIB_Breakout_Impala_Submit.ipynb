{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "Mcn2u4_qyY6w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-2U0JhEEcHd"
      },
      "outputs": [],
      "source": [
        "!pip install 'ray[rllib]' torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXJwGg5iGpWH"
      },
      "outputs": [],
      "source": [
        "!pip install gym\\[atari,accept-rom-license\\]==0.21.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "esqNwUNGya9q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBVp533jEg5z",
        "outputId": "09907245-673d-4368-8e48-8d32d24b160f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-04-13 14:17:26,730\tINFO worker.py:879 -- Calling ray.init() again after it has already been called.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "\n",
        "import ray\n",
        "import gym\n",
        "import ray.rllib.agents.ppo as ppo\n",
        "from ray.rllib.agents.impala import impala\n",
        "from ray.tune.logger import pretty_print\n",
        "\n",
        "ray.init(ignore_reinit_error=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2AEkt8NSPUc"
      },
      "outputs": [],
      "source": [
        "from ray.rllib.env.env_context import EnvContext\n",
        "from ray.rllib.models import ModelCatalog\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to gray scale\n",
        "def convert_to_gray(img):\n",
        "    return np.dot(img, [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "def normalize(img):\n",
        "    return img / 255\n",
        "\n",
        "# putting everything together\n",
        "def preprocess(img):\n",
        "    #img_g = convert_to_gray_rescale(img)\n",
        "    img_g = convert_to_gray(img)\n",
        "    img_t = resize(img_g, (84, 84))\n",
        "    img_n = normalize(img_t)\n",
        "    return img_n"
      ],
      "metadata": {
        "id": "9eFC7HNPSFNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENV_NAME = \"Breakout-v0\"\n",
        "env = gym.make(ENV_NAME)"
      ],
      "metadata": {
        "id": "odwCblBdS_KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = np.zeros((84,84))"
      ],
      "metadata": {
        "id": "LwX6__spTKq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Wrapper"
      ],
      "metadata": {
        "id": "aAeZeYMDyfcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.spaces import Discrete, Box\n",
        "\n",
        "class AtariEnv(gym.Env):\n",
        "    \"\"\"Class that wrapps the Dungeon Environment to make it \n",
        "    compatible with RLLib.\"\"\"\n",
        "\n",
        "    def __init__(self, config: EnvContext):\n",
        "\n",
        "        self.env = gym.make(\"Breakout-v0\")\n",
        "        self.input_shape = (84,84)\n",
        "        self.action_space = env.action_space\n",
        "\n",
        "        zeros = np.zeros(self.input_shape)\n",
        "        ones = np.ones(self.input_shape)\n",
        "        self.observation_space = Box(low=zeros, high=ones, shape=self.input_shape, dtype=np.float32)\n",
        "        \n",
        "    def reset(self):\n",
        "        obs = self.env.reset()\n",
        "        obs = self.preprocess(obs)\n",
        "        return obs\n",
        "\n",
        "    def step(self, action):\n",
        "        assert action in [i for i in range(self.env.action_space.n)]\n",
        "        obs, reward, done, _ = self.env.step(action)\n",
        "        obs = self.preprocess(obs)\n",
        "        return obs, reward, done, {}\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        random.seed(seed)\n",
        "\n",
        "    def preprocess(self, obs):\n",
        "        # We normalize and concatenate observations\n",
        "        obs = np.dot(obs, [0.2989, 0.5870, 0.1140])\n",
        "        obs = resize(obs, self.input_shape)\n",
        "        obs /= 255\n",
        "        return obs"
      ],
      "metadata": {
        "id": "ctFHtaVkSV6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cHtiGh4En7R"
      },
      "outputs": [],
      "source": [
        "config = impala.DEFAULT_CONFIG.copy()\n",
        "config['env'] = AtariEnv\n",
        "config[\"framework\"] = \"torch\"\n",
        "config[\"num_gpus\"] = 1\n",
        "config['num_workers'] = 8\n",
        "\n",
        "#print(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7UART17E-pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8eaa68-0171-4a8c-cba1-14b1226862d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_disable_action_flattening: false\n",
            "_disable_execution_plan_api: false\n",
            "_disable_preprocessor_api: false\n",
            "_fake_gpus: false\n",
            "_lr_vf: 0.0005\n",
            "_separate_vf_optimizer: false\n",
            "_tf_policy_handles_more_than_one_loss: false\n",
            "actions_in_input_normalized: false\n",
            "always_attach_evaluation_results: false\n",
            "batch_mode: truncate_episodes\n",
            "broadcast_interval: 1\n",
            "callbacks: <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>\n",
            "clip_actions: false\n",
            "collect_metrics_timeout: -1\n",
            "compress_observations: false\n",
            "create_env_on_driver: false\n",
            "custom_resources_per_worker: {}\n",
            "decay: 0.99\n",
            "eager_max_retraces: 20\n",
            "eager_tracing: false\n",
            "entropy_coeff: 0.01\n",
            "env: <class '__main__.AtariEnv'>\n",
            "env_config: {}\n",
            "epsilon: 0.1\n",
            "evaluation_config: {}\n",
            "evaluation_duration: 10\n",
            "evaluation_duration_unit: episodes\n",
            "evaluation_num_episodes: -1\n",
            "evaluation_num_workers: 0\n",
            "evaluation_parallel_to_training: false\n",
            "exploration_config:\n",
            "  type: StochasticSampling\n",
            "explore: true\n",
            "extra_python_environs_for_driver: {}\n",
            "extra_python_environs_for_worker: {}\n",
            "fake_sampler: false\n",
            "framework: torch\n",
            "gamma: 0.99\n",
            "grad_clip: 40.0\n",
            "ignore_worker_failures: false\n",
            "in_evaluation: false\n",
            "input: sampler\n",
            "input_config: {}\n",
            "input_evaluation:\n",
            "- is\n",
            "- wis\n",
            "learner_queue_size: 16\n",
            "learner_queue_timeout: 300\n",
            "local_tf_session_args:\n",
            "  inter_op_parallelism_threads: 8\n",
            "  intra_op_parallelism_threads: 8\n",
            "log_level: WARN\n",
            "log_sys_usage: true\n",
            "lr: 0.0005\n",
            "max_sample_requests_in_flight_per_worker: 2\n",
            "metrics_episode_collection_timeout_s: 180\n",
            "metrics_num_episodes_for_smoothing: 100\n",
            "metrics_smoothing_episodes: -1\n",
            "min_iter_time_s: -1\n",
            "min_time_s_per_reporting: 10\n",
            "minibatch_buffer_size: 1\n",
            "model:\n",
            "  _disable_action_flattening: false\n",
            "  _disable_preprocessor_api: false\n",
            "  _time_major: false\n",
            "  _use_default_native_models: false\n",
            "  attention_dim: 64\n",
            "  attention_head_dim: 32\n",
            "  attention_init_gru_gate_bias: 2.0\n",
            "  attention_memory_inference: 50\n",
            "  attention_memory_training: 50\n",
            "  attention_num_heads: 1\n",
            "  attention_num_transformer_units: 1\n",
            "  attention_position_wise_mlp_dim: 32\n",
            "  attention_use_n_prev_actions: 0\n",
            "  attention_use_n_prev_rewards: 0\n",
            "  conv_activation: relu\n",
            "  conv_filters: null\n",
            "  custom_action_dist: null\n",
            "  custom_model: null\n",
            "  custom_model_config: {}\n",
            "  custom_preprocessor: null\n",
            "  dim: 84\n",
            "  fcnet_activation: tanh\n",
            "  fcnet_hiddens:\n",
            "  - 256\n",
            "  - 256\n",
            "  framestack: true\n",
            "  free_log_std: false\n",
            "  grayscale: false\n",
            "  lstm_cell_size: 256\n",
            "  lstm_use_prev_action: false\n",
            "  lstm_use_prev_action_reward: -1\n",
            "  lstm_use_prev_reward: false\n",
            "  max_seq_len: 20\n",
            "  no_final_linear: false\n",
            "  post_fcnet_activation: relu\n",
            "  post_fcnet_hiddens: []\n",
            "  use_attention: false\n",
            "  use_lstm: false\n",
            "  vf_share_layers: true\n",
            "  zero_mean: true\n",
            "momentum: 0.0\n",
            "monitor: -1\n",
            "multiagent:\n",
            "  count_steps_by: env_steps\n",
            "  observation_fn: null\n",
            "  policies: {}\n",
            "  policies_to_train: null\n",
            "  policy_map_cache: null\n",
            "  policy_map_capacity: 100\n",
            "  policy_mapping_fn: null\n",
            "  replay_mode: independent\n",
            "no_done_at_end: false\n",
            "normalize_actions: true\n",
            "num_aggregation_workers: 0\n",
            "num_cpus_for_driver: 1\n",
            "num_cpus_per_worker: 1\n",
            "num_data_loader_buffers: -1\n",
            "num_envs_per_worker: 1\n",
            "num_gpus: 1\n",
            "num_gpus_per_worker: 0\n",
            "num_multi_gpu_tower_stacks: 1\n",
            "num_sgd_iter: 1\n",
            "num_workers: 8\n",
            "observation_filter: NoFilter\n",
            "opt_type: adam\n",
            "optimizer: {}\n",
            "output_compress_columns:\n",
            "- obs\n",
            "- new_obs\n",
            "output_max_file_size: 67108864\n",
            "placement_strategy: PACK\n",
            "postprocess_inputs: false\n",
            "preprocessor_pref: deepmind\n",
            "record_env: false\n",
            "remote_env_batch_wait_ms: 0\n",
            "remote_worker_envs: false\n",
            "render_env: false\n",
            "replay_buffer_num_slots: 0\n",
            "replay_proportion: 0.0\n",
            "rollout_fragment_length: 50\n",
            "sample_async: false\n",
            "sample_collector: <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>\n",
            "shuffle_buffer_size: 0\n",
            "simple_optimizer: -1\n",
            "soft_horizon: false\n",
            "synchronize_filters: true\n",
            "tf_session_args:\n",
            "  allow_soft_placement: true\n",
            "  device_count:\n",
            "    CPU: 1\n",
            "  gpu_options:\n",
            "    allow_growth: true\n",
            "  inter_op_parallelism_threads: 2\n",
            "  intra_op_parallelism_threads: 2\n",
            "  log_device_placement: false\n",
            "timesteps_per_iteration: 0\n",
            "train_batch_size: 500\n",
            "vf_loss_coeff: 0.5\n",
            "vtrace: true\n",
            "vtrace_clip_pg_rho_threshold: 1.0\n",
            "vtrace_clip_rho_threshold: 1.0\n",
            "vtrace_drop_last_ts: true\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(pretty_print(config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xymGzGfzGWcw"
      },
      "outputs": [],
      "source": [
        "#config['model']['fcnet_activation'] = 'relu'\n",
        "#config['use_critic'] = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "9PsEqwPoy1Ql"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0HQHnLwEyPK"
      },
      "outputs": [],
      "source": [
        "trainer = impala.ImpalaTrainer(config=config)\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "318f1WKiGhB4",
        "outputId": "c8c712a8-11b1-4dc1-ebf2-cd9397390d77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean rewards: 0.0 Min rewards: 0.0 Max rewards: 0.0\n",
            "Mean rewards: 1.564102564102564 Min rewards: 0.0 Max rewards: 5.0\n",
            "Mean rewards: 1.6282051282051282 Min rewards: 0.0 Max rewards: 5.0\n",
            "Mean rewards: 1.67 Min rewards: 0.0 Max rewards: 5.0\n",
            "Mean rewards: 1.64 Min rewards: 0.0 Max rewards: 4.0\n",
            "Mean rewards: 1.77 Min rewards: 0.0 Max rewards: 4.0\n",
            "Mean rewards: 1.83 Min rewards: 0.0 Max rewards: 4.0\n",
            "Mean rewards: 1.89 Min rewards: 0.0 Max rewards: 8.0\n",
            "Mean rewards: 1.93 Min rewards: 0.0 Max rewards: 8.0\n",
            "Mean rewards: 1.87 Min rewards: 0.0 Max rewards: 8.0\n",
            "Mean rewards: 2.01 Min rewards: 0.0 Max rewards: 7.0\n",
            "Mean rewards: 2.01 Min rewards: 0.0 Max rewards: 7.0\n",
            "Mean rewards: 2.43 Min rewards: 0.0 Max rewards: 7.0\n",
            "Mean rewards: 2.53 Min rewards: 0.0 Max rewards: 6.0\n",
            "Mean rewards: 2.4 Min rewards: 0.0 Max rewards: 8.0\n",
            "Mean rewards: 2.29 Min rewards: 0.0 Max rewards: 8.0\n",
            "Mean rewards: 2.03 Min rewards: 0.0 Max rewards: 8.0\n",
            "Mean rewards: 2.18 Min rewards: 0.0 Max rewards: 6.0\n",
            "Mean rewards: 2.31 Min rewards: 0.0 Max rewards: 6.0\n",
            "Mean rewards: 2.58 Min rewards: 0.0 Max rewards: 9.0\n",
            "Mean rewards: 2.83 Min rewards: 0.0 Max rewards: 9.0\n",
            "Mean rewards: 2.8 Min rewards: 0.0 Max rewards: 9.0\n",
            "Mean rewards: 2.8 Min rewards: 0.0 Max rewards: 9.0\n",
            "Mean rewards: 2.91 Min rewards: 0.0 Max rewards: 9.0\n",
            "Mean rewards: 2.81 Min rewards: 0.0 Max rewards: 9.0\n",
            "Mean rewards: 2.99 Min rewards: 0.0 Max rewards: 9.0\n",
            "Mean rewards: 3.24 Min rewards: 0.0 Max rewards: 9.0\n",
            "Mean rewards: 3.35 Min rewards: 0.0 Max rewards: 8.0\n",
            "Mean rewards: 3.57 Min rewards: 0.0 Max rewards: 8.0\n",
            "Mean rewards: 3.7 Min rewards: 0.0 Max rewards: 9.0\n",
            "Mean rewards: 3.87 Min rewards: 0.0 Max rewards: 9.0\n",
            "Mean rewards: 4.29 Min rewards: 1.0 Max rewards: 11.0\n",
            "Mean rewards: 4.34 Min rewards: 1.0 Max rewards: 11.0\n",
            "Mean rewards: 4.61 Min rewards: 1.0 Max rewards: 11.0\n",
            "Mean rewards: 4.72 Min rewards: 1.0 Max rewards: 11.0\n",
            "Mean rewards: 4.66 Min rewards: 1.0 Max rewards: 9.0\n",
            "Mean rewards: 5.15 Min rewards: 1.0 Max rewards: 14.0\n",
            "Mean rewards: 5.49 Min rewards: 1.0 Max rewards: 14.0\n",
            "Mean rewards: 5.72 Min rewards: 1.0 Max rewards: 15.0\n",
            "Mean rewards: 5.84 Min rewards: 1.0 Max rewards: 15.0\n",
            "Mean rewards: 6.05 Min rewards: 2.0 Max rewards: 15.0\n",
            "Mean rewards: 5.86 Min rewards: 2.0 Max rewards: 15.0\n",
            "Mean rewards: 5.74 Min rewards: 2.0 Max rewards: 15.0\n",
            "Mean rewards: 5.92 Min rewards: 0.0 Max rewards: 13.0\n",
            "Mean rewards: 6.3 Min rewards: 0.0 Max rewards: 16.0\n",
            "Mean rewards: 7.19 Min rewards: 0.0 Max rewards: 25.0\n",
            "Mean rewards: 7.67 Min rewards: 0.0 Max rewards: 25.0\n",
            "Mean rewards: 8.07 Min rewards: 0.0 Max rewards: 25.0\n",
            "Mean rewards: 8.5 Min rewards: 0.0 Max rewards: 25.0\n",
            "Mean rewards: 8.69 Min rewards: 1.0 Max rewards: 25.0\n",
            "Mean rewards: 8.54 Min rewards: 2.0 Max rewards: 25.0\n",
            "Mean rewards: 8.14 Min rewards: 2.0 Max rewards: 18.0\n",
            "Mean rewards: 8.04 Min rewards: 2.0 Max rewards: 18.0\n",
            "Mean rewards: 8.13 Min rewards: 2.0 Max rewards: 22.0\n",
            "Mean rewards: 8.5 Min rewards: 2.0 Max rewards: 22.0\n",
            "Mean rewards: 8.72 Min rewards: 2.0 Max rewards: 22.0\n",
            "Mean rewards: 8.77 Min rewards: 2.0 Max rewards: 22.0\n",
            "Mean rewards: 8.87 Min rewards: 3.0 Max rewards: 22.0\n",
            "Mean rewards: 8.89 Min rewards: 3.0 Max rewards: 22.0\n",
            "Mean rewards: 8.84 Min rewards: 3.0 Max rewards: 16.0\n",
            "Mean rewards: 8.7 Min rewards: 3.0 Max rewards: 18.0\n",
            "Mean rewards: 8.77 Min rewards: 3.0 Max rewards: 18.0\n",
            "Mean rewards: 9.07 Min rewards: 3.0 Max rewards: 18.0\n",
            "Mean rewards: 9.38 Min rewards: 3.0 Max rewards: 24.0\n",
            "Mean rewards: 9.46 Min rewards: 4.0 Max rewards: 24.0\n",
            "Mean rewards: 9.52 Min rewards: 4.0 Max rewards: 24.0\n",
            "Mean rewards: 9.74 Min rewards: 4.0 Max rewards: 24.0\n",
            "Mean rewards: 10.23 Min rewards: 4.0 Max rewards: 24.0\n",
            "Mean rewards: 10.37 Min rewards: 4.0 Max rewards: 24.0\n",
            "Mean rewards: 10.36 Min rewards: 4.0 Max rewards: 24.0\n",
            "Mean rewards: 10.8 Min rewards: 4.0 Max rewards: 21.0\n",
            "Mean rewards: 11.13 Min rewards: 3.0 Max rewards: 21.0\n",
            "Mean rewards: 11.39 Min rewards: 3.0 Max rewards: 21.0\n",
            "Mean rewards: 11.8 Min rewards: 3.0 Max rewards: 21.0\n",
            "Mean rewards: 11.83 Min rewards: 3.0 Max rewards: 23.0\n",
            "Mean rewards: 11.71 Min rewards: 3.0 Max rewards: 23.0\n",
            "Mean rewards: 12.05 Min rewards: 3.0 Max rewards: 30.0\n",
            "Mean rewards: 12.16 Min rewards: 3.0 Max rewards: 30.0\n",
            "Mean rewards: 11.98 Min rewards: 5.0 Max rewards: 30.0\n",
            "Mean rewards: 11.97 Min rewards: 6.0 Max rewards: 30.0\n",
            "Mean rewards: 12.13 Min rewards: 6.0 Max rewards: 30.0\n",
            "Mean rewards: 12.29 Min rewards: 6.0 Max rewards: 30.0\n",
            "Mean rewards: 12.28 Min rewards: 6.0 Max rewards: 30.0\n",
            "Mean rewards: 12.32 Min rewards: 6.0 Max rewards: 30.0\n",
            "Mean rewards: 12.28 Min rewards: 6.0 Max rewards: 28.0\n",
            "Mean rewards: 12.67 Min rewards: 6.0 Max rewards: 28.0\n",
            "Mean rewards: 12.83 Min rewards: 6.0 Max rewards: 28.0\n",
            "Mean rewards: 13.07 Min rewards: 6.0 Max rewards: 28.0\n",
            "Mean rewards: 12.67 Min rewards: 5.0 Max rewards: 28.0\n",
            "Mean rewards: 12.65 Min rewards: 5.0 Max rewards: 28.0\n",
            "Mean rewards: 13.04 Min rewards: 5.0 Max rewards: 28.0\n",
            "Mean rewards: 13.12 Min rewards: 5.0 Max rewards: 30.0\n",
            "Mean rewards: 13.21 Min rewards: 5.0 Max rewards: 30.0\n",
            "Mean rewards: 12.88 Min rewards: 5.0 Max rewards: 30.0\n",
            "Mean rewards: 13.07 Min rewards: 5.0 Max rewards: 30.0\n",
            "Mean rewards: 12.81 Min rewards: 5.0 Max rewards: 30.0\n",
            "Mean rewards: 13.37 Min rewards: 6.0 Max rewards: 30.0\n",
            "Mean rewards: 13.61 Min rewards: 6.0 Max rewards: 30.0\n",
            "Mean rewards: 13.34 Min rewards: 6.0 Max rewards: 30.0\n",
            "Mean rewards: 13.28 Min rewards: 5.0 Max rewards: 25.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(100):\n",
        "    # Perform one iteration of training the policy with PPO\n",
        "    result = trainer.train()\n",
        "\n",
        "    print(\"Mean rewards:\", result[\"episode_reward_mean\"],\"Min rewards:\", result['episode_reward_min'], \"Max rewards:\", result['episode_reward_max'])\n",
        "\n",
        "    #print(pretty_print(result))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continue Training\n"
      ],
      "metadata": {
        "id": "m4mhUYJxyzfG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNhmjsJhfL63",
        "outputId": "ee646705-cebe-4918-c3ca-544ea05432be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Mean rewards: 37.29 Min rewards: 7.0 Max rewards: 282.0\n",
            "Epoch: 1\n",
            "Mean rewards: 37.37 Min rewards: 7.0 Max rewards: 282.0\n",
            "Epoch: 2\n",
            "Mean rewards: 37.51 Min rewards: 7.0 Max rewards: 282.0\n",
            "Epoch: 3\n",
            "Mean rewards: 38.33 Min rewards: 7.0 Max rewards: 282.0\n",
            "Epoch: 4\n",
            "Mean rewards: 38.26 Min rewards: 7.0 Max rewards: 282.0\n",
            "Epoch: 5\n",
            "Mean rewards: 35.88 Min rewards: 7.0 Max rewards: 67.0\n",
            "Epoch: 6\n",
            "Mean rewards: 35.57 Min rewards: 7.0 Max rewards: 67.0\n",
            "Epoch: 7\n",
            "Mean rewards: 35.87 Min rewards: 7.0 Max rewards: 67.0\n",
            "Epoch: 8\n",
            "Mean rewards: 36.01 Min rewards: 7.0 Max rewards: 67.0\n",
            "Epoch: 9\n",
            "Mean rewards: 36.43 Min rewards: 7.0 Max rewards: 67.0\n",
            "Epoch: 10\n",
            "Mean rewards: 36.63 Min rewards: 7.0 Max rewards: 67.0\n",
            "Epoch: 11\n",
            "Mean rewards: 37.69 Min rewards: 14.0 Max rewards: 67.0\n",
            "Epoch: 12\n",
            "Mean rewards: 36.08 Min rewards: 11.0 Max rewards: 74.0\n",
            "Epoch: 13\n",
            "Mean rewards: 35.62 Min rewards: 11.0 Max rewards: 74.0\n",
            "Epoch: 14\n",
            "Mean rewards: 35.45 Min rewards: 11.0 Max rewards: 74.0\n",
            "Epoch: 15\n",
            "Mean rewards: 36.16 Min rewards: 11.0 Max rewards: 74.0\n",
            "Epoch: 16\n",
            "Mean rewards: 35.57 Min rewards: 11.0 Max rewards: 74.0\n",
            "Epoch: 17\n",
            "Mean rewards: 36.47 Min rewards: 11.0 Max rewards: 191.0\n",
            "Epoch: 18\n",
            "Mean rewards: 35.96 Min rewards: 11.0 Max rewards: 191.0\n",
            "Epoch: 19\n",
            "Mean rewards: 36.6 Min rewards: 11.0 Max rewards: 191.0\n",
            "Epoch: 20\n",
            "Mean rewards: 36.46 Min rewards: 11.0 Max rewards: 191.0\n",
            "Epoch: 21\n",
            "Mean rewards: 36.88 Min rewards: 11.0 Max rewards: 191.0\n",
            "Epoch: 22\n",
            "Mean rewards: 37.24 Min rewards: 11.0 Max rewards: 191.0\n",
            "Epoch: 23\n",
            "Mean rewards: 36.6 Min rewards: 11.0 Max rewards: 191.0\n",
            "Epoch: 24\n",
            "Mean rewards: 36.48 Min rewards: 11.0 Max rewards: 191.0\n",
            "Epoch: 25\n",
            "Mean rewards: 36.36 Min rewards: 11.0 Max rewards: 191.0\n",
            "Epoch: 26\n",
            "Mean rewards: 37.91 Min rewards: 13.0 Max rewards: 191.0\n",
            "Epoch: 27\n",
            "Mean rewards: 39.07 Min rewards: 14.0 Max rewards: 191.0\n",
            "Epoch: 28\n",
            "Mean rewards: 38.32 Min rewards: 14.0 Max rewards: 191.0\n",
            "Epoch: 29\n",
            "Mean rewards: 38.59 Min rewards: 14.0 Max rewards: 191.0\n",
            "Epoch: 30\n",
            "Mean rewards: 39.2 Min rewards: 14.0 Max rewards: 191.0\n",
            "Epoch: 31\n",
            "Mean rewards: 38.38 Min rewards: 14.0 Max rewards: 86.0\n",
            "Epoch: 32\n",
            "Mean rewards: 38.93 Min rewards: 14.0 Max rewards: 86.0\n",
            "Epoch: 33\n",
            "Mean rewards: 39.76 Min rewards: 15.0 Max rewards: 86.0\n",
            "Epoch: 34\n",
            "Mean rewards: 39.71 Min rewards: 15.0 Max rewards: 89.0\n",
            "Epoch: 35\n",
            "Mean rewards: 40.08 Min rewards: 15.0 Max rewards: 89.0\n",
            "Epoch: 36\n",
            "Mean rewards: 40.27 Min rewards: 15.0 Max rewards: 89.0\n",
            "Epoch: 37\n",
            "Mean rewards: 40.04 Min rewards: 14.0 Max rewards: 89.0\n",
            "Epoch: 38\n",
            "Mean rewards: 40.87 Min rewards: 14.0 Max rewards: 89.0\n",
            "Epoch: 39\n",
            "Mean rewards: 40.1 Min rewards: 14.0 Max rewards: 89.0\n",
            "Epoch: 40\n",
            "Mean rewards: 40.22 Min rewards: 14.0 Max rewards: 89.0\n",
            "Epoch: 41\n",
            "Mean rewards: 38.87 Min rewards: 12.0 Max rewards: 89.0\n",
            "Epoch: 42\n",
            "Mean rewards: 39.03 Min rewards: 12.0 Max rewards: 89.0\n",
            "Epoch: 43\n",
            "Mean rewards: 38.99 Min rewards: 12.0 Max rewards: 89.0\n",
            "Epoch: 44\n",
            "Mean rewards: 38.02 Min rewards: 12.0 Max rewards: 89.0\n",
            "Epoch: 45\n",
            "Mean rewards: 37.13 Min rewards: 12.0 Max rewards: 89.0\n",
            "Epoch: 46\n",
            "Mean rewards: 36.42 Min rewards: 12.0 Max rewards: 89.0\n",
            "Epoch: 47\n",
            "Mean rewards: 36.04 Min rewards: 12.0 Max rewards: 84.0\n",
            "Epoch: 48\n",
            "Mean rewards: 35.83 Min rewards: 12.0 Max rewards: 84.0\n",
            "Epoch: 49\n",
            "Mean rewards: 36.0 Min rewards: 12.0 Max rewards: 84.0\n",
            "Epoch: 50\n",
            "Mean rewards: 35.08 Min rewards: 12.0 Max rewards: 81.0\n",
            "Epoch: 51\n",
            "Mean rewards: 35.37 Min rewards: 12.0 Max rewards: 81.0\n",
            "Epoch: 52\n",
            "Mean rewards: 35.46 Min rewards: 12.0 Max rewards: 77.0\n",
            "Epoch: 53\n",
            "Mean rewards: 35.76 Min rewards: 12.0 Max rewards: 77.0\n",
            "Epoch: 54\n",
            "Mean rewards: 36.89 Min rewards: 12.0 Max rewards: 79.0\n",
            "Epoch: 55\n",
            "Mean rewards: 37.79 Min rewards: 12.0 Max rewards: 79.0\n",
            "Epoch: 56\n",
            "Mean rewards: 38.14 Min rewards: 13.0 Max rewards: 79.0\n",
            "Epoch: 57\n",
            "Mean rewards: 38.46 Min rewards: 13.0 Max rewards: 79.0\n",
            "Epoch: 58\n",
            "Mean rewards: 38.2 Min rewards: 7.0 Max rewards: 79.0\n",
            "Epoch: 59\n",
            "Mean rewards: 38.54 Min rewards: 7.0 Max rewards: 79.0\n",
            "Epoch: 60\n",
            "Mean rewards: 39.99 Min rewards: 7.0 Max rewards: 79.0\n",
            "Epoch: 61\n",
            "Mean rewards: 39.48 Min rewards: 7.0 Max rewards: 79.0\n",
            "Epoch: 62\n",
            "Mean rewards: 40.1 Min rewards: 7.0 Max rewards: 79.0\n",
            "Epoch: 63\n",
            "Mean rewards: 40.52 Min rewards: 7.0 Max rewards: 81.0\n",
            "Epoch: 64\n",
            "Mean rewards: 40.81 Min rewards: 7.0 Max rewards: 81.0\n",
            "Epoch: 65\n",
            "Mean rewards: 41.05 Min rewards: 7.0 Max rewards: 81.0\n",
            "Epoch: 66\n",
            "Mean rewards: 41.9 Min rewards: 7.0 Max rewards: 89.0\n",
            "Epoch: 67\n",
            "Mean rewards: 41.27 Min rewards: 7.0 Max rewards: 89.0\n",
            "Epoch: 68\n",
            "Mean rewards: 41.21 Min rewards: 7.0 Max rewards: 89.0\n",
            "Epoch: 69\n",
            "Mean rewards: 40.17 Min rewards: 7.0 Max rewards: 89.0\n",
            "Epoch: 70\n",
            "Mean rewards: 40.44 Min rewards: 7.0 Max rewards: 89.0\n",
            "Epoch: 71\n",
            "Mean rewards: 40.64 Min rewards: 7.0 Max rewards: 89.0\n",
            "Epoch: 72\n",
            "Mean rewards: 40.49 Min rewards: 7.0 Max rewards: 89.0\n",
            "Epoch: 73\n",
            "Mean rewards: 41.7 Min rewards: 13.0 Max rewards: 89.0\n",
            "Epoch: 74\n",
            "Mean rewards: 42.56 Min rewards: 13.0 Max rewards: 89.0\n",
            "Epoch: 75\n",
            "Mean rewards: 42.27 Min rewards: 13.0 Max rewards: 89.0\n",
            "Epoch: 76\n",
            "Mean rewards: 43.16 Min rewards: 13.0 Max rewards: 89.0\n",
            "Epoch: 77\n",
            "Mean rewards: 43.62 Min rewards: 13.0 Max rewards: 89.0\n",
            "Epoch: 78\n",
            "Mean rewards: 43.18 Min rewards: 13.0 Max rewards: 89.0\n",
            "Epoch: 79\n",
            "Mean rewards: 42.94 Min rewards: 13.0 Max rewards: 89.0\n",
            "Epoch: 80\n",
            "Mean rewards: 42.67 Min rewards: 13.0 Max rewards: 89.0\n",
            "Epoch: 81\n",
            "Mean rewards: 42.4 Min rewards: 13.0 Max rewards: 74.0\n",
            "Epoch: 82\n",
            "Mean rewards: 42.34 Min rewards: 13.0 Max rewards: 74.0\n",
            "Epoch: 83\n",
            "Mean rewards: 42.56 Min rewards: 17.0 Max rewards: 74.0\n",
            "Epoch: 84\n",
            "Mean rewards: 42.68 Min rewards: 17.0 Max rewards: 74.0\n",
            "Epoch: 85\n",
            "Mean rewards: 42.39 Min rewards: 17.0 Max rewards: 74.0\n",
            "Epoch: 86\n",
            "Mean rewards: 41.92 Min rewards: 13.0 Max rewards: 74.0\n",
            "Epoch: 87\n",
            "Mean rewards: 41.33 Min rewards: 13.0 Max rewards: 74.0\n",
            "Epoch: 88\n",
            "Mean rewards: 41.59 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 89\n",
            "Mean rewards: 41.52 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 90\n",
            "Mean rewards: 41.91 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 91\n",
            "Mean rewards: 41.74 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 92\n",
            "Mean rewards: 41.6 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 93\n",
            "Mean rewards: 42.4 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 94\n",
            "Mean rewards: 42.37 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 95\n",
            "Mean rewards: 43.96 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 96\n",
            "Mean rewards: 44.37 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 97\n",
            "Mean rewards: 44.49 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 98\n",
            "Mean rewards: 44.19 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 99\n",
            "Mean rewards: 45.29 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 100\n",
            "Mean rewards: 45.85 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 101\n",
            "Mean rewards: 46.8 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 102\n",
            "Mean rewards: 48.06 Min rewards: 13.0 Max rewards: 116.0\n",
            "Epoch: 103\n",
            "Mean rewards: 49.48 Min rewards: 16.0 Max rewards: 116.0\n",
            "Epoch: 104\n",
            "Mean rewards: 49.25 Min rewards: 16.0 Max rewards: 95.0\n",
            "Epoch: 105\n",
            "Mean rewards: 50.04 Min rewards: 16.0 Max rewards: 95.0\n",
            "Epoch: 106\n",
            "Mean rewards: 50.57 Min rewards: 16.0 Max rewards: 95.0\n",
            "Epoch: 107\n",
            "Mean rewards: 50.12 Min rewards: 16.0 Max rewards: 95.0\n",
            "Epoch: 108\n",
            "Mean rewards: 49.82 Min rewards: 16.0 Max rewards: 95.0\n",
            "Epoch: 109\n",
            "Mean rewards: 49.5 Min rewards: 16.0 Max rewards: 95.0\n",
            "Epoch: 110\n",
            "Mean rewards: 49.2 Min rewards: 16.0 Max rewards: 95.0\n",
            "Epoch: 111\n",
            "Mean rewards: 48.47 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 112\n",
            "Mean rewards: 48.68 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 113\n",
            "Mean rewards: 48.77 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 114\n",
            "Mean rewards: 49.09 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 115\n",
            "Mean rewards: 49.23 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 116\n",
            "Mean rewards: 49.61 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 117\n",
            "Mean rewards: 49.9 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 118\n",
            "Mean rewards: 49.74 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 119\n",
            "Mean rewards: 49.33 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 120\n",
            "Mean rewards: 50.72 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 121\n",
            "Mean rewards: 51.11 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 122\n",
            "Mean rewards: 50.79 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 123\n",
            "Mean rewards: 50.05 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 124\n",
            "Mean rewards: 50.07 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 125\n",
            "Mean rewards: 50.98 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 126\n",
            "Mean rewards: 51.78 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 127\n",
            "Mean rewards: 52.68 Min rewards: 10.0 Max rewards: 126.0\n",
            "Epoch: 128\n",
            "Mean rewards: 53.48 Min rewards: 19.0 Max rewards: 97.0\n",
            "Epoch: 129\n",
            "Mean rewards: 53.51 Min rewards: 19.0 Max rewards: 97.0\n",
            "Epoch: 130\n",
            "Mean rewards: 53.84 Min rewards: 19.0 Max rewards: 97.0\n",
            "Epoch: 131\n",
            "Mean rewards: 54.68 Min rewards: 21.0 Max rewards: 97.0\n",
            "Epoch: 132\n",
            "Mean rewards: 54.54 Min rewards: 16.0 Max rewards: 97.0\n",
            "Epoch: 133\n",
            "Mean rewards: 53.63 Min rewards: 14.0 Max rewards: 97.0\n",
            "Epoch: 134\n",
            "Mean rewards: 52.36 Min rewards: 14.0 Max rewards: 97.0\n",
            "Epoch: 135\n",
            "Mean rewards: 52.45 Min rewards: 14.0 Max rewards: 97.0\n",
            "Epoch: 136\n",
            "Mean rewards: 52.2 Min rewards: 14.0 Max rewards: 97.0\n",
            "Epoch: 137\n",
            "Mean rewards: 51.25 Min rewards: 14.0 Max rewards: 92.0\n",
            "Epoch: 138\n",
            "Mean rewards: 50.14 Min rewards: 14.0 Max rewards: 92.0\n",
            "Epoch: 139\n",
            "Mean rewards: 50.16 Min rewards: 14.0 Max rewards: 92.0\n",
            "Epoch: 140\n",
            "Mean rewards: 49.66 Min rewards: 11.0 Max rewards: 92.0\n",
            "Epoch: 141\n",
            "Mean rewards: 48.66 Min rewards: 11.0 Max rewards: 92.0\n",
            "Epoch: 142\n",
            "Mean rewards: 49.1 Min rewards: 11.0 Max rewards: 92.0\n",
            "Epoch: 143\n",
            "Mean rewards: 49.04 Min rewards: 11.0 Max rewards: 92.0\n",
            "Epoch: 144\n",
            "Mean rewards: 49.04 Min rewards: 11.0 Max rewards: 92.0\n",
            "Epoch: 145\n",
            "Mean rewards: 48.99 Min rewards: 11.0 Max rewards: 99.0\n",
            "Epoch: 146\n",
            "Mean rewards: 49.35 Min rewards: 11.0 Max rewards: 99.0\n",
            "Epoch: 147\n",
            "Mean rewards: 49.43 Min rewards: 11.0 Max rewards: 99.0\n",
            "Epoch: 148\n",
            "Mean rewards: 50.6 Min rewards: 11.0 Max rewards: 102.0\n",
            "Epoch: 149\n",
            "Mean rewards: 50.76 Min rewards: 11.0 Max rewards: 102.0\n",
            "Epoch: 150\n",
            "Mean rewards: 52.52 Min rewards: 11.0 Max rewards: 102.0\n",
            "Epoch: 151\n",
            "Mean rewards: 53.04 Min rewards: 11.0 Max rewards: 102.0\n",
            "Epoch: 152\n",
            "Mean rewards: 53.05 Min rewards: 11.0 Max rewards: 102.0\n",
            "Epoch: 153\n",
            "Mean rewards: 54.04 Min rewards: 11.0 Max rewards: 102.0\n",
            "Epoch: 154\n",
            "Mean rewards: 54.22 Min rewards: 11.0 Max rewards: 102.0\n",
            "Epoch: 155\n",
            "Mean rewards: 55.03 Min rewards: 11.0 Max rewards: 102.0\n",
            "Epoch: 156\n",
            "Mean rewards: 54.59 Min rewards: 14.0 Max rewards: 102.0\n",
            "Epoch: 157\n",
            "Mean rewards: 54.72 Min rewards: 14.0 Max rewards: 102.0\n",
            "Epoch: 158\n",
            "Mean rewards: 55.94 Min rewards: 14.0 Max rewards: 102.0\n",
            "Epoch: 159\n",
            "Mean rewards: 55.36 Min rewards: 14.0 Max rewards: 102.0\n",
            "Epoch: 160\n",
            "Mean rewards: 54.63 Min rewards: 14.0 Max rewards: 102.0\n",
            "Epoch: 161\n",
            "Mean rewards: 53.96 Min rewards: 14.0 Max rewards: 102.0\n",
            "Epoch: 162\n",
            "Mean rewards: 53.9 Min rewards: 14.0 Max rewards: 102.0\n",
            "Epoch: 163\n",
            "Mean rewards: 54.17 Min rewards: 14.0 Max rewards: 102.0\n",
            "Epoch: 164\n",
            "Mean rewards: 53.21 Min rewards: 14.0 Max rewards: 97.0\n",
            "Epoch: 165\n",
            "Mean rewards: 53.69 Min rewards: 14.0 Max rewards: 97.0\n",
            "Epoch: 166\n",
            "Mean rewards: 46.68 Min rewards: 1.0 Max rewards: 97.0\n",
            "Epoch: 167\n",
            "Mean rewards: 43.93 Min rewards: 1.0 Max rewards: 88.0\n",
            "Epoch: 168\n",
            "Mean rewards: 43.76 Min rewards: 1.0 Max rewards: 88.0\n",
            "Epoch: 169\n",
            "Mean rewards: 43.54 Min rewards: 1.0 Max rewards: 88.0\n",
            "Epoch: 170\n",
            "Mean rewards: 43.85 Min rewards: 1.0 Max rewards: 88.0\n",
            "Epoch: 171\n",
            "Mean rewards: 47.28 Min rewards: 1.0 Max rewards: 315.0\n",
            "Epoch: 172\n",
            "Mean rewards: 47.34 Min rewards: 1.0 Max rewards: 315.0\n",
            "Epoch: 173\n",
            "Mean rewards: 46.65 Min rewards: 1.0 Max rewards: 315.0\n",
            "Epoch: 174\n",
            "Mean rewards: 47.33 Min rewards: 1.0 Max rewards: 315.0\n",
            "Epoch: 175\n",
            "Mean rewards: 49.64 Min rewards: 1.0 Max rewards: 315.0\n",
            "Epoch: 176\n",
            "Mean rewards: 49.54 Min rewards: 1.0 Max rewards: 315.0\n",
            "Epoch: 177\n",
            "Mean rewards: 49.57 Min rewards: 1.0 Max rewards: 315.0\n",
            "Epoch: 178\n",
            "Mean rewards: 49.48 Min rewards: 1.0 Max rewards: 315.0\n",
            "Epoch: 179\n",
            "Mean rewards: 49.61 Min rewards: 1.0 Max rewards: 315.0\n",
            "Epoch: 180\n",
            "Mean rewards: 48.82 Min rewards: 1.0 Max rewards: 315.0\n",
            "Epoch: 181\n",
            "Mean rewards: 49.93 Min rewards: 1.0 Max rewards: 315.0\n",
            "Epoch: 182\n",
            "Mean rewards: 51.26 Min rewards: 2.0 Max rewards: 315.0\n",
            "Epoch: 183\n",
            "Mean rewards: 55.1 Min rewards: 3.0 Max rewards: 315.0\n",
            "Epoch: 184\n",
            "Mean rewards: 57.39 Min rewards: 12.0 Max rewards: 315.0\n",
            "Epoch: 185\n",
            "Mean rewards: 58.68 Min rewards: 18.0 Max rewards: 315.0\n",
            "Epoch: 186\n",
            "Mean rewards: 58.71 Min rewards: 18.0 Max rewards: 315.0\n",
            "Epoch: 187\n",
            "Mean rewards: 59.83 Min rewards: 18.0 Max rewards: 315.0\n",
            "Epoch: 188\n",
            "Mean rewards: 57.35 Min rewards: 18.0 Max rewards: 240.0\n",
            "Epoch: 189\n",
            "Mean rewards: 57.55 Min rewards: 18.0 Max rewards: 240.0\n",
            "Epoch: 190\n",
            "Mean rewards: 58.31 Min rewards: 18.0 Max rewards: 240.0\n",
            "Epoch: 191\n",
            "Mean rewards: 60.24 Min rewards: 18.0 Max rewards: 240.0\n",
            "Epoch: 192\n",
            "Mean rewards: 57.72 Min rewards: 18.0 Max rewards: 111.0\n",
            "Epoch: 193\n",
            "Mean rewards: 58.31 Min rewards: 18.0 Max rewards: 111.0\n",
            "Epoch: 194\n",
            "Mean rewards: 58.5 Min rewards: 18.0 Max rewards: 111.0\n",
            "Epoch: 195\n",
            "Mean rewards: 60.13 Min rewards: 18.0 Max rewards: 120.0\n",
            "Epoch: 196\n",
            "Mean rewards: 62.52 Min rewards: 18.0 Max rewards: 253.0\n",
            "Epoch: 197\n",
            "Mean rewards: 62.71 Min rewards: 18.0 Max rewards: 253.0\n",
            "Epoch: 198\n",
            "Mean rewards: 63.54 Min rewards: 18.0 Max rewards: 253.0\n",
            "Epoch: 199\n",
            "Mean rewards: 64.66 Min rewards: 18.0 Max rewards: 253.0\n",
            "Epoch: 200\n",
            "Mean rewards: 64.95 Min rewards: 18.0 Max rewards: 253.0\n",
            "Epoch: 201\n",
            "Mean rewards: 64.8 Min rewards: 18.0 Max rewards: 253.0\n",
            "Epoch: 202\n",
            "Mean rewards: 66.75 Min rewards: 18.0 Max rewards: 253.0\n",
            "Epoch: 203\n",
            "Mean rewards: 66.54 Min rewards: 18.0 Max rewards: 253.0\n",
            "Epoch: 204\n",
            "Mean rewards: 66.64 Min rewards: 18.0 Max rewards: 253.0\n",
            "Epoch: 205\n",
            "Mean rewards: 66.78 Min rewards: 18.0 Max rewards: 253.0\n",
            "Epoch: 206\n",
            "Mean rewards: 67.19 Min rewards: 18.0 Max rewards: 253.0\n",
            "Epoch: 207\n",
            "Mean rewards: 68.58 Min rewards: 18.0 Max rewards: 253.0\n",
            "Epoch: 208\n",
            "Mean rewards: 70.5 Min rewards: 18.0 Max rewards: 261.0\n",
            "Epoch: 209\n",
            "Mean rewards: 70.39 Min rewards: 18.0 Max rewards: 261.0\n",
            "Epoch: 210\n",
            "Mean rewards: 73.13 Min rewards: 18.0 Max rewards: 308.0\n",
            "Epoch: 211\n",
            "Mean rewards: 73.2 Min rewards: 18.0 Max rewards: 308.0\n",
            "Epoch: 212\n",
            "Mean rewards: 73.65 Min rewards: 18.0 Max rewards: 308.0\n",
            "Epoch: 213\n",
            "Mean rewards: 72.96 Min rewards: 18.0 Max rewards: 308.0\n",
            "Epoch: 214\n",
            "Mean rewards: 70.76 Min rewards: 16.0 Max rewards: 308.0\n",
            "Epoch: 215\n",
            "Mean rewards: 71.56 Min rewards: 16.0 Max rewards: 308.0\n",
            "Epoch: 216\n",
            "Mean rewards: 69.44 Min rewards: 13.0 Max rewards: 308.0\n",
            "Epoch: 217\n",
            "Mean rewards: 68.55 Min rewards: 10.0 Max rewards: 308.0\n",
            "Epoch: 218\n",
            "Mean rewards: 67.34 Min rewards: 10.0 Max rewards: 308.0\n",
            "Epoch: 219\n",
            "Mean rewards: 67.28 Min rewards: 10.0 Max rewards: 308.0\n",
            "Epoch: 220\n",
            "Mean rewards: 65.56 Min rewards: 10.0 Max rewards: 308.0\n",
            "Epoch: 221\n",
            "Mean rewards: 66.42 Min rewards: 10.0 Max rewards: 308.0\n",
            "Epoch: 222\n",
            "Mean rewards: 64.7 Min rewards: 10.0 Max rewards: 308.0\n",
            "Epoch: 223\n",
            "Mean rewards: 65.11 Min rewards: 10.0 Max rewards: 308.0\n",
            "Epoch: 224\n",
            "Mean rewards: 65.53 Min rewards: 10.0 Max rewards: 308.0\n",
            "Epoch: 225\n",
            "Mean rewards: 63.15 Min rewards: 10.0 Max rewards: 308.0\n",
            "Epoch: 226\n",
            "Mean rewards: 62.25 Min rewards: 10.0 Max rewards: 308.0\n",
            "Epoch: 227\n",
            "Mean rewards: 59.22 Min rewards: 10.0 Max rewards: 103.0\n",
            "Epoch: 228\n",
            "Mean rewards: 59.56 Min rewards: 10.0 Max rewards: 144.0\n",
            "Epoch: 229\n",
            "Mean rewards: 59.57 Min rewards: 10.0 Max rewards: 144.0\n",
            "Epoch: 230\n",
            "Mean rewards: 59.63 Min rewards: 10.0 Max rewards: 144.0\n",
            "Epoch: 231\n",
            "Mean rewards: 59.39 Min rewards: 10.0 Max rewards: 144.0\n",
            "Epoch: 232\n",
            "Mean rewards: 59.52 Min rewards: 10.0 Max rewards: 144.0\n",
            "Epoch: 233\n",
            "Mean rewards: 58.87 Min rewards: 10.0 Max rewards: 144.0\n",
            "Epoch: 234\n",
            "Mean rewards: 59.61 Min rewards: 10.0 Max rewards: 144.0\n",
            "Epoch: 235\n",
            "Mean rewards: 61.36 Min rewards: 21.0 Max rewards: 144.0\n",
            "Epoch: 236\n",
            "Mean rewards: 62.61 Min rewards: 21.0 Max rewards: 144.0\n",
            "Epoch: 237\n",
            "Mean rewards: 62.34 Min rewards: 17.0 Max rewards: 144.0\n",
            "Epoch: 238\n",
            "Mean rewards: 62.54 Min rewards: 17.0 Max rewards: 144.0\n",
            "Epoch: 239\n",
            "Mean rewards: 63.34 Min rewards: 17.0 Max rewards: 144.0\n",
            "Epoch: 240\n",
            "Mean rewards: 63.8 Min rewards: 17.0 Max rewards: 144.0\n",
            "Epoch: 241\n",
            "Mean rewards: 63.23 Min rewards: 17.0 Max rewards: 144.0\n",
            "Epoch: 242\n",
            "Mean rewards: 63.14 Min rewards: 17.0 Max rewards: 144.0\n",
            "Epoch: 243\n",
            "Mean rewards: 62.24 Min rewards: 17.0 Max rewards: 144.0\n",
            "Epoch: 244\n",
            "Mean rewards: 63.31 Min rewards: 17.0 Max rewards: 144.0\n",
            "Epoch: 245\n",
            "Mean rewards: 63.07 Min rewards: 17.0 Max rewards: 144.0\n",
            "Epoch: 246\n",
            "Mean rewards: 65.61 Min rewards: 17.0 Max rewards: 299.0\n",
            "Epoch: 247\n",
            "Mean rewards: 64.66 Min rewards: 17.0 Max rewards: 299.0\n",
            "Epoch: 248\n",
            "Mean rewards: 65.07 Min rewards: 17.0 Max rewards: 299.0\n",
            "Epoch: 249\n",
            "Mean rewards: 65.04 Min rewards: 17.0 Max rewards: 299.0\n",
            "Epoch: 250\n",
            "Mean rewards: 65.45 Min rewards: 17.0 Max rewards: 299.0\n",
            "Epoch: 251\n",
            "Mean rewards: 65.01 Min rewards: 17.0 Max rewards: 299.0\n",
            "Epoch: 252\n",
            "Mean rewards: 65.71 Min rewards: 17.0 Max rewards: 299.0\n",
            "Epoch: 253\n",
            "Mean rewards: 65.65 Min rewards: 17.0 Max rewards: 299.0\n",
            "Epoch: 254\n",
            "Mean rewards: 66.47 Min rewards: 17.0 Max rewards: 299.0\n",
            "Epoch: 255\n",
            "Mean rewards: 66.51 Min rewards: 17.0 Max rewards: 299.0\n",
            "Epoch: 256\n",
            "Mean rewards: 66.81 Min rewards: 19.0 Max rewards: 299.0\n",
            "Epoch: 257\n",
            "Mean rewards: 65.87 Min rewards: 19.0 Max rewards: 299.0\n",
            "Epoch: 258\n",
            "Mean rewards: 65.27 Min rewards: 19.0 Max rewards: 299.0\n",
            "Epoch: 259\n",
            "Mean rewards: 66.11 Min rewards: 19.0 Max rewards: 299.0\n",
            "Epoch: 260\n",
            "Mean rewards: 65.5 Min rewards: 19.0 Max rewards: 299.0\n",
            "Epoch: 261\n",
            "Mean rewards: 65.89 Min rewards: 20.0 Max rewards: 299.0\n",
            "Epoch: 262\n",
            "Mean rewards: 66.28 Min rewards: 20.0 Max rewards: 299.0\n",
            "Epoch: 263\n",
            "Mean rewards: 67.36 Min rewards: 20.0 Max rewards: 299.0\n",
            "Epoch: 264\n",
            "Mean rewards: 64.56 Min rewards: 20.0 Max rewards: 119.0\n",
            "Epoch: 265\n",
            "Mean rewards: 64.84 Min rewards: 20.0 Max rewards: 119.0\n",
            "Epoch: 266\n",
            "Mean rewards: 64.45 Min rewards: 20.0 Max rewards: 119.0\n",
            "Epoch: 267\n",
            "Mean rewards: 65.25 Min rewards: 20.0 Max rewards: 119.0\n",
            "Epoch: 268\n",
            "Mean rewards: 65.2 Min rewards: 20.0 Max rewards: 119.0\n",
            "Epoch: 269\n",
            "Mean rewards: 65.87 Min rewards: 20.0 Max rewards: 119.0\n",
            "Epoch: 270\n",
            "Mean rewards: 68.18 Min rewards: 20.0 Max rewards: 168.0\n",
            "Epoch: 271\n",
            "Mean rewards: 68.15 Min rewards: 20.0 Max rewards: 168.0\n",
            "Epoch: 272\n",
            "Mean rewards: 67.18 Min rewards: 20.0 Max rewards: 168.0\n",
            "Epoch: 273\n",
            "Mean rewards: 67.35 Min rewards: 20.0 Max rewards: 168.0\n",
            "Epoch: 274\n",
            "Mean rewards: 68.0 Min rewards: 20.0 Max rewards: 222.0\n",
            "Epoch: 275\n",
            "Mean rewards: 67.59 Min rewards: 20.0 Max rewards: 222.0\n",
            "Epoch: 276\n",
            "Mean rewards: 68.57 Min rewards: 20.0 Max rewards: 222.0\n",
            "Epoch: 277\n",
            "Mean rewards: 66.55 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 278\n",
            "Mean rewards: 66.79 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 279\n",
            "Mean rewards: 66.35 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 280\n",
            "Mean rewards: 65.26 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 281\n",
            "Mean rewards: 65.09 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 282\n",
            "Mean rewards: 64.47 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 283\n",
            "Mean rewards: 64.85 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 284\n",
            "Mean rewards: 65.79 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 285\n",
            "Mean rewards: 65.2 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 286\n",
            "Mean rewards: 64.55 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 287\n",
            "Mean rewards: 64.26 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 288\n",
            "Mean rewards: 62.86 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 289\n",
            "Mean rewards: 63.18 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 290\n",
            "Mean rewards: 62.39 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 291\n",
            "Mean rewards: 62.32 Min rewards: 15.0 Max rewards: 222.0\n",
            "Epoch: 292\n",
            "Mean rewards: 61.55 Min rewards: 15.0 Max rewards: 139.0\n",
            "Epoch: 293\n",
            "Mean rewards: 61.7 Min rewards: 15.0 Max rewards: 139.0\n",
            "Epoch: 294\n",
            "Mean rewards: 62.62 Min rewards: 15.0 Max rewards: 144.0\n",
            "Epoch: 295\n",
            "Mean rewards: 64.2 Min rewards: 22.0 Max rewards: 144.0\n",
            "Epoch: 296\n",
            "Mean rewards: 65.37 Min rewards: 25.0 Max rewards: 144.0\n",
            "Epoch: 297\n",
            "Mean rewards: 65.28 Min rewards: 25.0 Max rewards: 144.0\n",
            "Epoch: 298\n",
            "Mean rewards: 67.24 Min rewards: 25.0 Max rewards: 144.0\n",
            "Epoch: 299\n",
            "Mean rewards: 70.0 Min rewards: 25.0 Max rewards: 232.0\n",
            "Epoch: 300\n",
            "Mean rewards: 69.7 Min rewards: 19.0 Max rewards: 232.0\n",
            "Epoch: 301\n",
            "Mean rewards: 70.41 Min rewards: 19.0 Max rewards: 232.0\n",
            "Epoch: 302\n",
            "Mean rewards: 70.21 Min rewards: 19.0 Max rewards: 232.0\n",
            "Epoch: 303\n",
            "Mean rewards: 70.57 Min rewards: 19.0 Max rewards: 232.0\n",
            "Epoch: 304\n",
            "Mean rewards: 71.22 Min rewards: 19.0 Max rewards: 232.0\n",
            "Epoch: 305\n",
            "Mean rewards: 73.5 Min rewards: 19.0 Max rewards: 232.0\n",
            "Epoch: 306\n",
            "Mean rewards: 75.06 Min rewards: 19.0 Max rewards: 232.0\n",
            "Epoch: 307\n",
            "Mean rewards: 75.4 Min rewards: 19.0 Max rewards: 232.0\n",
            "Epoch: 308\n",
            "Mean rewards: 76.2 Min rewards: 19.0 Max rewards: 232.0\n",
            "Epoch: 309\n",
            "Mean rewards: 76.71 Min rewards: 19.0 Max rewards: 232.0\n",
            "Epoch: 310\n",
            "Mean rewards: 76.84 Min rewards: 19.0 Max rewards: 232.0\n",
            "Epoch: 311\n",
            "Mean rewards: 79.42 Min rewards: 19.0 Max rewards: 292.0\n",
            "Epoch: 312\n",
            "Mean rewards: 79.85 Min rewards: 19.0 Max rewards: 292.0\n",
            "Epoch: 313\n",
            "Mean rewards: 79.74 Min rewards: 19.0 Max rewards: 292.0\n",
            "Epoch: 314\n",
            "Mean rewards: 79.78 Min rewards: 19.0 Max rewards: 292.0\n",
            "Epoch: 315\n",
            "Mean rewards: 80.08 Min rewards: 19.0 Max rewards: 292.0\n",
            "Epoch: 316\n",
            "Mean rewards: 81.57 Min rewards: 19.0 Max rewards: 292.0\n",
            "Epoch: 317\n",
            "Mean rewards: 81.63 Min rewards: 19.0 Max rewards: 292.0\n",
            "Epoch: 318\n",
            "Mean rewards: 82.05 Min rewards: 19.0 Max rewards: 292.0\n",
            "Epoch: 319\n",
            "Mean rewards: 79.27 Min rewards: 19.0 Max rewards: 292.0\n",
            "Epoch: 320\n",
            "Mean rewards: 78.03 Min rewards: 15.0 Max rewards: 292.0\n",
            "Epoch: 321\n",
            "Mean rewards: 78.34 Min rewards: 15.0 Max rewards: 292.0\n",
            "Epoch: 322\n",
            "Mean rewards: 78.83 Min rewards: 15.0 Max rewards: 292.0\n",
            "Epoch: 323\n",
            "Mean rewards: 77.51 Min rewards: 15.0 Max rewards: 292.0\n",
            "Epoch: 324\n",
            "Mean rewards: 76.26 Min rewards: 15.0 Max rewards: 292.0\n",
            "Epoch: 325\n",
            "Mean rewards: 75.27 Min rewards: 15.0 Max rewards: 292.0\n",
            "Epoch: 326\n",
            "Mean rewards: 77.7 Min rewards: 15.0 Max rewards: 292.0\n",
            "Epoch: 327\n",
            "Mean rewards: 78.54 Min rewards: 15.0 Max rewards: 292.0\n",
            "Epoch: 328\n",
            "Mean rewards: 78.1 Min rewards: 15.0 Max rewards: 292.0\n",
            "Epoch: 329\n",
            "Mean rewards: 78.58 Min rewards: 15.0 Max rewards: 292.0\n",
            "Epoch: 330\n",
            "Mean rewards: 75.96 Min rewards: 15.0 Max rewards: 238.0\n",
            "Epoch: 331\n",
            "Mean rewards: 77.24 Min rewards: 15.0 Max rewards: 238.0\n",
            "Epoch: 332\n",
            "Mean rewards: 76.85 Min rewards: 15.0 Max rewards: 238.0\n",
            "Epoch: 333\n",
            "Mean rewards: 76.57 Min rewards: 15.0 Max rewards: 238.0\n",
            "Epoch: 334\n",
            "Mean rewards: 76.75 Min rewards: 15.0 Max rewards: 238.0\n",
            "Epoch: 335\n",
            "Mean rewards: 77.59 Min rewards: 15.0 Max rewards: 238.0\n",
            "Epoch: 336\n",
            "Mean rewards: 79.03 Min rewards: 15.0 Max rewards: 238.0\n",
            "Epoch: 337\n",
            "Mean rewards: 79.6 Min rewards: 15.0 Max rewards: 238.0\n",
            "Epoch: 338\n",
            "Mean rewards: 80.67 Min rewards: 15.0 Max rewards: 238.0\n",
            "Epoch: 339\n",
            "Mean rewards: 84.47 Min rewards: 20.0 Max rewards: 324.0\n",
            "Epoch: 340\n",
            "Mean rewards: 85.02 Min rewards: 20.0 Max rewards: 324.0\n",
            "Epoch: 341\n",
            "Mean rewards: 85.24 Min rewards: 20.0 Max rewards: 324.0\n",
            "Epoch: 342\n",
            "Mean rewards: 86.02 Min rewards: 20.0 Max rewards: 324.0\n",
            "Epoch: 343\n",
            "Mean rewards: 86.55 Min rewards: 20.0 Max rewards: 324.0\n",
            "Epoch: 344\n",
            "Mean rewards: 88.44 Min rewards: 20.0 Max rewards: 324.0\n",
            "Epoch: 345\n",
            "Mean rewards: 87.5 Min rewards: 20.0 Max rewards: 324.0\n",
            "Epoch: 346\n",
            "Mean rewards: 87.11 Min rewards: 20.0 Max rewards: 324.0\n",
            "Epoch: 347\n",
            "Mean rewards: 87.21 Min rewards: 20.0 Max rewards: 324.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(400):\n",
        "    # Perform one iteration of training the policy with Impala\n",
        "    result = trainer.train()\n",
        "    print(\"Epoch:\", i)\n",
        "    print(\"Mean rewards:\", result[\"episode_reward_mean\"],\"Min rewards:\", result['episode_reward_min'], \"Max rewards:\", result['episode_reward_max'])\n",
        "\n",
        "    #print(pretty_print(result))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw-U9jG-Hnjo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "RRLIB Breakout-Impala - Submit.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}